{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "208f17a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b147c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_svhn_data(data_dir='../data/raw', split='train'):      # '../data/raw' is where I put my data files. Change it to yours\n",
    "    \"\"\"\n",
    "    Loads SVHN cropped digit data from .mat files.\n",
    "    \n",
    "    Args:\n",
    "        data_dir (str): Path to the folder containing .mat files.\n",
    "        split (str): 'train' or 'test'.\n",
    "        \n",
    "    Returns:\n",
    "        X (np.array): Images of shape (N, 32, 32, 3) -> Normalized [0, 1]\n",
    "        y (np.array): Labels of shape (N,) -> Corrected so '0' is class 0 (not 10)\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(data_dir, f'{split}_32x32.mat')\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}. Please download it from http://ufldl.stanford.edu/housenumbers/\")\n",
    "\n",
    "    print(f\"Loading {split} data from {file_path}...\")\n",
    "    mat_data = scipy.io.loadmat(file_path)\n",
    "    \n",
    "    # The .mat file has X shape: (32, 32, 3, N) -> (Height, Width, Channels, Batch)\n",
    "    # We want standard shape: (N, 32, 32, 3) for visualization/processing\n",
    "    X = mat_data['X']\n",
    "    X = np.transpose(X, (3, 0, 1, 2))\n",
    "    \n",
    "    # Normalize pixel values to [0, 1] range (Standard for Deep Learning)\n",
    "    X = X.astype('float32') / 255.0\n",
    "\n",
    "    # The .mat file has y shape: (N, 1). Flatten it to (N,)\n",
    "    y = mat_data['y'].flatten()\n",
    "    \n",
    "    # FIX LABELS: SVHN labels '0' as 10. We need to map 10 -> 0.\n",
    "    y[y == 10] = 0\n",
    "    \n",
    "    print(f\"Loaded {X.shape[0]} samples.\")\n",
    "    print(f\"X shape: {X.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d65404f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      "Loading train data from ../data/raw/train_32x32.mat...\n",
      "Loaded 73257 samples.\n",
      "X shape: (73257, 32, 32, 3)\n",
      "y shape: (73257,)\n",
      "Loading test data from ../data/raw/test_32x32.mat...\n",
      "Loaded 26032 samples.\n",
      "X shape: (26032, 32, 32, 3)\n",
      "y shape: (26032,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Data...\")\n",
    "X_train, y_train = load_svhn_data('../data/raw', split='train')\n",
    "X_val, y_val = load_svhn_data('../data/raw', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ddc34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define standard ResNet Normalization (required for pre-trained weights)\n",
    "# Mean and Std for ImageNet dataset which is the pre-training model we using, NOT RADNOM DATA but actual statistic from ImageNet\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edce406b",
   "metadata": {},
   "source": [
    "ResNet-18 Residual Neural Network with 18 layers is what we used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec85995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_resnet(X, y, batch_size, shuffle):\n",
    "    # 1. Convert to Tensor (N, 32, 32, 3) -> (N, 3, 32, 32)\n",
    "    tensor_x = torch.Tensor(X).permute(0, 3, 1, 2)\n",
    "    \n",
    "    # 2. Normalize channel-wise manually\n",
    "    # (ResNet expects normalized inputs)\n",
    "    for c in range(3):\n",
    "        tensor_x[:, c, :, :] = (tensor_x[:, c, :, :] - mean[c]) / std[c]\n",
    "        \n",
    "    tensor_y = torch.Tensor(y).long()\n",
    "    \n",
    "    dataset = TensorDataset(tensor_x, tensor_y)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c02576",
   "metadata": {},
   "source": [
    "About ResNet, its basically NN with many layers, but with specialy residual layers that allows complex deep network to still be able to retain original gradients features. How is this done: Ouput(x) = F(F(x)) + x, the input x is passed to both NN and added again after two NN layers sums up the output. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac42bc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = preprocess_for_resnet(X_train, y_train, batch_size=64, shuffle=True)\n",
    "val_loader = preprocess_for_resnet(X_val, y_val, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5cc78d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "494126fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained ResNet18\n",
    "# 'weights=\"DEFAULT\"' loads the best available ImageNet weights\n",
    "resnet = models.resnet18(weights=\"DEFAULT\")     # this down loads the pre-trained weights\n",
    "\n",
    "# Freeze all layers (Optional: Unfreeze later for better accuracy)\n",
    "# We freeze them so we don't destroy the pre-trained knowledge initially\n",
    "# for param in resnet.parameters():\n",
    "#     param.requires_grad = False         # this is pretrained, so this preevents updating weights\n",
    "\n",
    "# Replace the final fully connected layer (fc)\n",
    "# In_features is 512 for ResNet18. We change output to 10 classes.\n",
    "num_ftrs = resnet.fc.in_features    \n",
    "resnet.fc = nn.Linear(num_ftrs, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5518bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to GPU\n",
    "resnet = resnet.to(device)\n",
    "# It physically moves the model's parameters from your computer's RAM to the GPU's VRAM. \n",
    "# If you don't do this, the GPU can't perform calculations on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b698698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Only optimize the final layer (fc) parameters initially\n",
    "optimizer = optim.Adam(resnet.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c8bdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Transfer Learning...\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5 # Transfer learning converges fast!\n",
    "train_losses = []\n",
    "val_errors = []\n",
    "\n",
    "print(\"Starting Transfer Learning...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    resnet.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # Validation\n",
    "    resnet.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = resnet(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    val_acc = 100 * correct / total\n",
    "    val_error = 100 - val_acc\n",
    "    val_errors.append(val_error)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | Val Error: {val_error:.2f}%\")\n",
    "\n",
    "# Plot Results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_errors, label='Val Error', color='orange')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SVHN Project)",
   "language": "python",
   "name": "svhn_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
